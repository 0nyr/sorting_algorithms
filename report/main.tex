\documentclass[compress,12pt]{beamer}

\usepackage{booktabs}

\usetheme{Arguelles}

\title{Sorts}
\subtitle{Understanding Array Sorting Algorithms, Efficiency, Comparison and Implementation}
\event{INSAlgo}
\date{\today}
\author{Onyr (Florian RASCOUSSIER)}
\institute{INSA Lyon \& IMT Atlantique}
\email{florian.rascoussier@insa-lyon.fr}
%\homepage{}
\github{0nyr}

\begin{document}

\frame[plain]{\titlepage}

\section{Introduction}

\begin{frame}
    \frametitle{Runtime and Memory Complexity: Basics}

    \begin{itemize}
          \item \textbf{Runtime Complexity}
                \begin{itemize}
                      \item Time an algorithm takes relative to input length.
                \end{itemize}
          \item \textbf{Memory Complexity}
                \begin{itemize}
                      \item Memory needed by an algorithm relative to input size.
                \end{itemize}
          \item Both are crucial for:
                \begin{itemize}
                      \item Comparing algorithm efficiency.
                      \item Choosing the right algorithm for the job.
                \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Measuring Program Execution Time: Challenges}
    \framesubtitle{Types of Time Measurements}

    \begin{itemize}
        \item \textbf{Time Measurement Issues}
              \begin{itemize}
                  \item Real Time: Wall-clock time for program execution.
                  \item User Time: CPU time for executing user program code.
                        \begin{itemize}
                            \item Excludes system operations.
                            \item Reflects direct program execution time.
                        \end{itemize}
                  \item System Time\footnote{See \url{https://stackoverflow.com/questions/556405/what-do-real-user-and-sys-mean-in-the-output-of-time1}}: CPU time for system operations for the program.
                        \begin{itemize}
                            \item File operations, I/O tasks.
                            \item Essential for resource-intensive operations.
                        \end{itemize}
              \end{itemize}
        \item Variability in measurements due to:
              \begin{itemize}
                  \item System load, resources, hardware.
                  \item Inconsistencies across environments.
              \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Measuring Program Execution Time: Theoretical Approach}
    \framesubtitle{Abstracting Time Measurements}

    \begin{itemize}
        \item \textbf{Theoretical Approach}
              \begin{itemize}
                  \item Approximate with \textbf{input size} (n) and \textbf{operation count}.
                  \item $n \in \mathbb{N}^*$: Number of loops or iterations -- main driver of complexity.
                  \item $k \in \mathbb{N}^*$: Parameters affecting complexity, aside from input size.
                        \begin{itemize}
                            \item Here intended as range of the non-negative key values
                        \end{itemize}
                  \item Focus on growth trends rather than exact times.
              \end{itemize}
        \item \textbf{Conclusion:}
              \begin{itemize}
                  \item Theoretical focus helps identify scalability issues.
                  \item Prioritizes relative efficiency over absolute timing.
              \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Understanding Big O Notation}

    \begin{itemize}
        \item \textbf{Big O Notation}: Describes the upper bound of complexity.
              \begin{itemize}
                  \item Focuses on worst-case scenario.
                  \item Ignores constant factors and lower order terms.
              \end{itemize}
        \item \textbf{Basic Rules}
              \begin{itemize}
                  \item \textit{Linear Terms}: $\mathcal{O}(\alpha n + \beta) = \mathcal{O}(n)$.
                        \begin{itemize}
                            \item Constants $\alpha$, $\beta$ don't affect growth rate.
                        \end{itemize}
                  \item \textit{Sum Rule}: $\mathcal{O}(f(n)) + \mathcal{O}(g(n)) = \mathcal{O}(\max(f(n), g(n)))$.
                  \item \textit{Product Rule}: $\mathcal{O}(f(n)) \cdot \mathcal{O}(g(n)) = \mathcal{O}(f(n) \cdot g(n))$.
              \end{itemize}
        \item \textbf{Implications}
              \begin{itemize}
                  \item Simplifies comparing algorithms.
                  \item Emphasizes dominant factors affecting growth.
              \end{itemize}
        \item \textbf{Example}
              \begin{itemize}
                  \item $\mathcal{O}(3n^2 + 10n + 100) = \mathcal{O}(n^2)$.
                        \begin{itemize}
                            \item $n^2$ term dominates as $n$ grows.
                        \end{itemize}
              \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Classic Sorting Algorithms and Their Complexities}
    \begin{table}
        \begin{tabular}{lcccc}
            \toprule
            Algo. & Best & Average & Worst & Mem. \\
            \midrule
            Selection Sort & $\mathcal{O}(n^2)$ & $\mathcal{O}(n^2)$ & $\mathcal{O}(n^2)$ & $\mathcal{O}(1)$ \\
            Insertion Sort & $\mathcal{O}(n)$ & $\mathcal{O}(n^2)$ & $\mathcal{O}(n^2)$ & $\mathcal{O}(1)$ \\
            Bubble Sort & $\mathcal{O}(n)$ & $\mathcal{O}(n^2)$ & $\mathcal{O}(n^2)$ & $\mathcal{O}(1)$ \\
            Merge Sort & $\mathcal{O}(n \log n)$ & $\mathcal{O}(n \log n)$ & $\mathcal{O}(n \log n)$ & $\mathcal{O}(n)$ \\
            Quick Sort & $\mathcal{O}(n \log n)$ & $\mathcal{O}(n \log n)$ & $\mathcal{O}(n^2)$ & $\mathcal{O}(\log n)$ \\
            \bottomrule
        \end{tabular}
    \end{table}
\end{frame}

\begin{frame}
    \frametitle{More Algorithms and Their Complexities\footnote{See \url{https://www.bigocheatsheet.com/}}}
    \begin{table}
        \scriptsize % Adjust font size to fit the table in the frame
        \begin{tabular}{lcccc}
            \toprule
            Algorithm & Best & Average & Worst & Memory \\
            \midrule
            Selection Sort & $\Omega(n^2)$ & $\Theta(n^2)$ & $O(n^2)$ & $O(1)$ \\
            Insertion Sort & $\Omega(n)$ & $\Theta(n^2)$ & $O(n^2)$ & $O(1)$ \\
            Bubble Sort & $\Omega(n)$ & $\Theta(n^2)$ & $O(n^2)$ & $O(1)$ \\
            Merge Sort & $\Omega(n \log n)$ & $\Theta(n \log n)$ & $O(n \log n)$ & $O(n)$ \\
            Quick Sort & $\Omega(n \log n)$ & $\Theta(n \log n)$ & $O(n^2)$ & $O(\log n)$ \\
            Timsort & $\Omega(n)$ & $\Theta(n \log n)$ & $O(n \log n)$ & $O(n)$ \\
            Heapsort & $\Omega(n \log n)$ & $\Theta(n \log n)$ & $O(n \log n)$ & $O(1)$ \\
            Tree Sort & $\Omega(n \log n)$ & $\Theta(n \log n)$ & $O(n^2)$ & $O(n)$ \\
            Shell Sort & $\Omega(n \log n)$ & $\Theta(n(\log n)^2)$ & $O(n(\log n)^2)$ & $O(1)$ \\
            Bucket Sort & $\Omega(n+k)$ & $\Theta(n+k)$ & $O(n^2)$ & $O(n)$ \\
            Radix Sort & $\Omega(nk)$ & $\Theta(nk)$ & $O(nk)$ & $O(n+k)$ \\
            Counting Sort & $\Omega(n+k)$ & $\Theta(n+k)$ & $O(n+k)$ & $O(k)$ \\
            Cubesort & $\Omega(n)$ & $\Theta(n \log n)$ & $O(n \log n)$ & $O(n)$ \\
            \bottomrule
        \end{tabular}
    \end{table}
\end{frame}



\end{document}
